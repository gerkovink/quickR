---
title: "Practical F"
author: "Gerko Vink"
date: "Statistical Programming in R"
output: html_document
---


```{r echo=FALSE}
knitr::opts_chunk$set(
  echo    = FALSE,
  include = FALSE,
  eval    = FALSE
)

```


---

#### Exercises

---

The following packages are required for this practical:
```{r, message=FALSE}
library(dplyr)
library(magrittr)
library(mice)
```
and if you'd like the same results as I have obtained, you can fix the random seed
```{r}
set.seed(123)
```

---

1. **Use a pipe to do the following:**

- draw 1000 values from a normal distribution with `mean = 5` and `sd = 1` - $N(5, 1)$, 
- create a matrix where the first 500 values are the first column and the second 500 values are the second column
- make a scatterplot of these two columns

---

2. **Use a pipe to calculate the correlation matrix on the `anscombe` data set**

```{r}
anscombe %>%
  cor()
```

---

3. **Now use a pipe to calculate the correlation for the pair (`x4`, `y4`) on the `anscombe` data set**

<!-- Using the standard `%>%` pipe: -->
```{r}
anscombe %>%
  subset(select = c(x4, y4)) %>%
  cor()
```
<!-- Alternatively, we can use the `%$%` pipe from package `magrittr` to make this process much more efficient. -->
```{r}
anscombe %$%
  cor(x4, y4)
```

---

4. **Use a pipe to calculate the correlation between `hgt` and `wgt` in the `boys` data set from package `mice`.**

<!-- Because `boys` has missings values for almost all variables, we must first select `wgt` and `hgt` and then omit the rows that have missing values, before we can calculate the correlation. Using the standard `%>%` pipe, this would look like: -->
```{r}
boys %>%
  subset(select = c("wgt", "hgt")) %>%
  cor(use = "pairwise.complete.obs")
```
<!-- which is equivalent to  -->
```{r}
boys %>%
  subset(select = c("wgt", "hgt")) %>%
  na.omit() %>%
  cor()
```

<!-- Alternatively, we can use the `%$%` pipe: -->
```{r}
boys %$% 
  cor(hgt, wgt, use = "pairwise.complete.obs")
```
<!-- The `%$%` pipe *unfolds* the listed dimensions of the `boys` dataset, such that we can refer to them directly.  -->

---

5. **In the `boys` data set, `hgt` is recorded in centimeters. Use a pipe to transform `hgt` in the `boys` dataset to height in meters and verify the transformation**

<!-- Using the standard `%>%` and the `%$%` pipes: -->
```{r}
boys %>%
  transform(hgt = hgt / 100) %$%
  mean(hgt, na.rm = TRUE)
```

---

6. **Use a pipe to plot the pair (`hgt`, `wgt`) two times: once for `hgt` in meters and once for `hgt` in centimeters. Make the points in the 'centimeter' plot `red` and in the 'meter' plot `blue`. **

<!-- This is best done with the `%T>%` pipe: -->
```{r}
boys %>%
  subset(select = c(hgt, wgt)) %T>%
  plot(col = "red", main = "Height in centimeters") %>%
  transform(hgt = hgt / 100) %>%
  plot(col = "blue", main = "Height in meters")
```

<!-- The `%T>%` pipe is very useful, because it creates a literal `T` junction in the pipe. It is perhaps most informative to graphically represent the above pipe as follows: -->
```{r eval=FALSE}
boys %>%
  subset(select = c(hgt, wgt)) %T>%
  plot(col = "red", main = "Height in centimeters") %>%
  transform(hgt = hgt / 100) %>%
  plot(col = "blue", main = "Height in meters")
```
![](flow_t_pipe.png)

<!-- We can see that there is indeed a literal T-junction. Naturally, we can expand this process with more `%T>%` pipes. However, once a pipe gets too long or too complicated, it is perhaps more useful to cut the piped problem into smaller, manageble pieces.  -->


---

7. **Generate two random samples of 10 numbers from a normal distribution with the below specifications. Test the null hypothesis that the population mean is 0.**

- $\mu = 0$ and $\sigma = 2$
- $\mu = 1.5$ and $\sigma = 2$

```{r}
x <- rnorm(10, mean = 0, sd = 2)
t.test(x)

x <- rnorm(10, 1.5, 2)
t.test(x)
```

---

8. **Write a function that generates a random sample of `n` numbers from a normal distribution with a user defined mean (i.e. a mean that you can choose when running the function) and standard deviation 1, and returns the `p.value` for the test that the mean is 0.**

```{r}
p.value.t <- function (n, mu) {
  x <- rnorm(n, mu, 1)
  t.test(x)$p.value
}

p.value.t(n = 30, mu = 3)
```

---


9. **Use the function of Exercise 8 to generate 50 $p$-values with $n=10,\mu=0$, and make a `qqplot` to compare distribution of the $p$-values with a uniform $[0,1]$ variable.**

```{r}
y <- numeric(50)
for (i in 1:50) {
  y[i] <- p.value.t(n = 10, mu = 0)
}

qqplot(x=qunif(ppoints(50)), y)
```

<!-- The p-values follow a uniform distribution.  -->

---

In a study that examined the use of acupuncture to treat migraine headaches, consenting patients on a waiting list for treatment for migraine were randomly assigned in a 2:1:1 ratio to acupuncture treatment, a "sham" acupuncture treatment in which needles were inserted at non-acupuncture points, and waiting-list patients whose only treatment was self-administered (Linde et al., 2005). The "sham" acupuncture treatment was described to trial participants as an acupuncture treatment that did not follow the principles of Chinese medicine. 

---

10. **What is the conclusion when the outcome is classified according to numbers of patients who experienced a greater than 50% reduction in headaches over a four-week period, relative to a pre-randomization baseline?**

Use the following data
```{r, echo=TRUE, include=TRUE}
data <- matrix(c(74, 71, 43, 38, 11, 65), nrow = 2, ncol = 3)
colnames(data) <- c("Acupuncture", "Sham", "Waiting list")
rownames(data) <- c("> 50% reduction", "< 50% reduction")
```

<!-- We start with calculating the $X^2$-test: -->
<!-- ```{r} -->

<!-- X2test <-  -->
<!--   data %>% -->
<!--   chisq.test() -->

<!-- X2test -->
<!-- ``` -->

<!-- which is extremely significant. We can then calculate the expected cell frequencies -->
<!-- ```{r} -->
<!-- X2test$expected -->
<!-- ``` -->
<!-- and the raw residual -->
<!-- ```{r} -->
<!-- X2test$observed - X2test$expected -->
<!-- ``` -->

<!-- as well as the Pearson residual -->
<!-- ```{r} -->
<!-- X2test$residuals -->
<!-- ``` -->
<!-- to infer the difference in observed and expected cell frequencies. Patients on the waiting list experience `> 50% reduction` much less than we would expect under independence of treatment and outcome. -->

---

11. **Patients who received the acupuncture and sham acupuncture treatments were asked to guess their treatment at the end of their trial. What would you conclude from this data?**

```{r, echo=TRUE, include = TRUE}
data <- matrix(c(82, 17, 30, 30, 26, 16), nrow = 3, ncol = 2)
colnames(data) <- c("Acupuncture", "Sham")
rownames(data) <- c("Chinese", "Other", "Don't know")
```

<!-- We again start with calculating the $X^2$-test: -->
<!-- ```{r} -->

<!-- X2test <-  -->
<!--   data %>% -->
<!--   chisq.test() -->

<!-- X2test -->
<!-- ``` -->

<!-- which is very significant. We can then calculate the expected cell frequencies -->
<!-- ```{r} -->
<!-- X2test$expected -->
<!-- ``` -->
<!-- and the raw residual -->
<!-- ```{r} -->
<!-- X2test$observed - X2test$expected -->
<!-- ``` -->

<!-- as well as the Pearson residual -->
<!-- ```{r} -->
<!-- X2test$residuals -->
<!-- ``` -->

<!-- We find that people who are receiving *true* `Acupuncture` are more inclined to believe that they receive `Chinese` acupuncture than we would expect under independence, while people wo received `Sham` acupuncture are more inclined to believe that they receive `Other` type of acupuncture. `Don't know` is more or less similarly distributed over the observed and expected frequencies. -->


---

End of Practical

---

#### Useful References

- [`magrittr`](https://magrittr.tidyverse.org)
- [`R` for Data Science](http://r4ds.had.co.nz) - [Chapter 18 on pipes](http://r4ds.had.co.nz/pipes.html)